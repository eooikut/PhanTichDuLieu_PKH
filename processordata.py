import pandas as pd
import re


# ==============================
# 1. X·ª¨ L√ù FILE L·ªÜNH S·∫¢N XU·∫§T
# ==============================

import re
import pandas as pd

def get_lsx_range_from_file(file_path, sheet_name=0, row_index=5, col_index=0):
    val = pd.read_excel(file_path, sheet_name=sheet_name, header=None).iloc[row_index, col_index]
    if pd.isna(val):
        return None, None

    text = str(val)
    found = re.findall(r"(\d{2}/\d{2}/\d{4})", text)

    if len(found) >= 2:
        start = pd.to_datetime(found[0], dayfirst=True, errors="coerce")
        end = pd.to_datetime(found[-1], dayfirst=True, errors="coerce")
    elif len(found) == 1:
        start = end = pd.to_datetime(found[0], dayfirst=True, errors="coerce")
    else:
        start = end = None

    return start, end

def extract_dates(val):
    """Tr√≠ch xu·∫•t ng√†y b·∫Øt ƒë·∫ßu/k·∫øt th√∫c t·ª´ chu·ªói th·ªùi gian."""
    if pd.isna(val):
        return None, None

    text = str(val).replace("\n", " ").strip()
    found = re.findall(r"(\d{2}/\d{2}/\d{4})", text)

    if len(found) >= 2:
        start = pd.to_datetime(found[0], dayfirst=True, errors="coerce")
        end = pd.to_datetime(found[-1], dayfirst=True, errors="coerce")
    elif len(found) == 1:
        start = end = pd.to_datetime(found[0], dayfirst=True, errors="coerce")
    else:
        start = end = None

    return start, end


def process_lsx(file_path, sheet_name=3, skip_rows=6):
    """ƒê·ªçc v√† x·ª≠ l√Ω file LSX."""
    time_col = "Th·ªùi gian d·ª± ki·∫øn SX\nTime/Date"
    df = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=skip_rows)

    # ƒêi·ªÅn gi√° tr·ªã th·ªùi gian cho c√°c d√≤ng tr·ªëng
    df[time_col] = df[time_col].ffill()

    # T·∫°o b·∫£ng block_days
    block_days = df[[time_col]].drop_duplicates().copy()
    block_days[["Ng√†y b·∫Øt ƒë·∫ßu block", "Ng√†y k·∫øt th√∫c block"]] = block_days[time_col].apply(
        lambda x: pd.Series(extract_dates(x))
    )

    # √âp ki·ªÉu datetime
    for col in ["Ng√†y b·∫Øt ƒë·∫ßu block", "Ng√†y k·∫øt th√∫c block"]:
        block_days[col] = pd.to_datetime(block_days[col], dayfirst=True, errors="coerce")

    # T√≠nh s·ªë ng√†y y√™u c·∫ßu block
    block_days["S·ªë ng√†y y√™u c·∫ßu block"] = (
        (block_days["Ng√†y k·∫øt th√∫c block"] - block_days["Ng√†y b·∫Øt ƒë·∫ßu block"]).dt.days + 1
    )

    # Merge l·∫°i v√†o df g·ªëc
    df = df.merge(block_days, on=time_col, how="left")
    df["S·ªë Order number"] = df["S·ªë Order number"].ffill()

    # Chuy·ªÉn c·ªôt SL sang s·ªë
    for col in ["Unnamed: 4", "Unnamed: 5"]:
        df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)

    # T√≠nh t·ªïng SL theo block
    agg_df = df.groupby(
        ["S·ªë Order number", "Ng√†y b·∫Øt ƒë·∫ßu block", "Ng√†y k·∫øt th√∫c block", "S·ªë ng√†y y√™u c·∫ßu block"],
        as_index=False
    ).agg({
        "Unnamed: 4": "sum",
        "Unnamed: 5": "sum"
    })

    agg_df["SL y√™u c·∫ßu (t·∫•n)"] = (agg_df["Unnamed: 4"] + agg_df["Unnamed: 5"]) * 1000
    agg_df["SL trung b√¨nh/ng√†y"] = agg_df["SL y√™u c·∫ßu (t·∫•n)"] / agg_df["S·ªë ng√†y y√™u c·∫ßu block"]

    # Chu·∫©n b·ªã d·ªØ li·ªáu ƒë·ªÉ merge
    df_req = agg_df.rename(columns={
        "S·ªë Order number": "Order",
        "SL y√™u c·∫ßu (t·∫•n)": "T·ªïng y√™u c·∫ßu"
    })[["Order", "T·ªïng y√™u c·∫ßu", "SL trung b√¨nh/ng√†y"]]

    return df_req



# ==============================
# 2. X·ª¨ L√ù FILE S·∫¢N L∆Ø·ª¢NG TH·ª∞C T·∫æ
# ==============================
def process_actual(file_path, sheet_name="Data"):
    """ƒê·ªçc v√† x·ª≠ l√Ω file s·∫£n l∆∞·ª£ng th·ª±c t·∫ø."""
    df = pd.read_excel(file_path, sheet_name=sheet_name).dropna(how="all")
    df["Ng√†y s·∫£n xu·∫•t"] = pd.to_datetime(df["Ng√†y s·∫£n xu·∫•t"], errors="coerce")
    df["Kh√¥ÃÅi l∆∞∆°Ã£ng"] = pd.to_numeric(df["Kh√¥ÃÅi l∆∞∆°Ã£ng"], errors="coerce")
    df = df.dropna(subset=["Order", "Ng√†y s·∫£n xu·∫•t"])

    # Gom nh√≥m theo Order v√† Ng√†y
    df_daily = df.groupby(["Order", "Ng√†y s·∫£n xu·∫•t"], as_index=False)["Kh√¥ÃÅi l∆∞∆°Ã£ng"].sum()
    df_daily = df_daily.rename(columns={
        "Kh√¥ÃÅi l∆∞∆°Ã£ng": "S·∫£n l∆∞·ª£ng th·ª±c t·∫ø",
        "Ng√†y s·∫£n xu·∫•t": "Ng√†y"
    })

    # T·ªïng s·∫£n l∆∞·ª£ng theo Order
    total_actual = df_daily.groupby("Order", as_index=False)["S·∫£n l∆∞·ª£ng th·ª±c t·∫ø"].sum()
    total_actual = total_actual.rename(columns={"S·∫£n l∆∞·ª£ng th·ª±c t·∫ø": "T·ªïng s·∫£n l∆∞·ª£ng th·ª±c t·∫ø"})

    return df_daily, total_actual
#3 X·ª¨ L√ù FILE S·∫¢N L∆Ø·ª¢NG KHO

def xu_ly_ton_kho(file_sanluong, file_kho):
    # ƒê·ªçc d·ªØ li·ªáu
    df_sanluong = pd.read_excel(file_sanluong)
    df_kho = pd.read_excel(file_kho)

    # B·ªè c√°c d√≤ng tr·ªëng ID Cu·ªôn B√≥
    df_kho = df_kho.dropna(subset=["ID Cu·ªôn B√≥"])
    df_sanluong = df_sanluong.dropna(subset=["ID Cu·ªôn B√≥"])

    # Chu·∫©n h√≥a ki·ªÉu d·ªØ li·ªáu
    df_kho["ID Cu·ªôn B√≥"] = df_kho["ID Cu·ªôn B√≥"].astype(str).str.strip()
    df_sanluong["ID Cu·ªôn B√≥"] = df_sanluong["ID Cu·ªôn B√≥"].astype(str).str.strip()

    # 1Ô∏è‚É£ X√°c ƒë·ªãnh cu·ªôn b√≥ ch∆∞a nh·∫≠p kho
    id_kho_set = set(df_kho["ID Cu·ªôn B√≥"].unique())
    df_chua_nhap = df_sanluong[~df_sanluong["ID Cu·ªôn B√≥"].isin(id_kho_set)].copy()

    # G·ªôp theo Order ƒë·ªÉ t√≠nh t·ªïng kh·ªëi l∆∞·ª£ng ch∆∞a nh·∫≠p kho
    df_chua_nhap_sum = df_chua_nhap.groupby("Order").agg(
        S·ªë_l∆∞·ª£ng_ch∆∞a_nh·∫≠p_kho=("Kh√¥ÃÅi l∆∞∆°Ã£ng", "sum")
    ).reset_index()

    # 2Ô∏è‚É£ Ph√¢n lo·∫°i t·ªìn kho
    df_kho["T·ªìn kho lo·∫°i"] = df_kho["SO Mapping"].apply(
        lambda x: "Kh√¥ng t·ª± do" if pd.notna(x) else "T·ª± do"
    )

    # 3Ô∏è‚É£ T·ªïng h·ª£p t·ªìn kho theo Order
    summary = df_kho.groupby("Order").agg(
        T·ªïng_t·ªìn_kho_t·ª±_do=("Kh√¥ÃÅi l∆∞∆°Ã£ng", lambda x: x[df_kho.loc[x.index, "T·ªìn kho lo·∫°i"] == "T·ª± do"].sum()),
        T·ªïng_t·ªìn_kho_mapping_SO=("Kh√¥ÃÅi l∆∞∆°Ã£ng", lambda x: x[df_kho.loc[x.index, "T·ªìn kho lo·∫°i"] == "Kh√¥ng t·ª± do"].sum()),
        T·ªïng_t·ªìn_kho=("Kh√¥ÃÅi l∆∞∆°Ã£ng", "sum")
    ).reset_index()

    # 4Ô∏è‚É£ Merge th√™m c·ªôt s·ªë l∆∞·ª£ng ch∆∞a nh·∫≠p kho
    summary = summary.merge(df_chua_nhap_sum, on="Order", how="left").fillna(0)
    # ƒê·ªïi t√™n c·ªôt
    summary = summary.rename(columns={
        "Order": "M√£ Order",
        "T·ªïng_t·ªìn_kho_t·ª±_do": "T·ªìn kho ch∆∞a Mapping SO",
        "T·ªïng_t·ªìn_kho_mapping_SO": "T·ªìn kho Mapping SO",
        "T·ªïng_t·ªìn_kho": "T·ªïng t·ªìn kho",
        "S·ªë_l∆∞·ª£ng_ch∆∞a_nh·∫≠p_kho": "S·ªë l∆∞·ª£ng ch·ªù nh·∫≠p kho"
    })

    # B·ªè .0 trong Order
    summary["M√£ Order"] = summary["M√£ Order"].astype(str).str.replace(r"\.0$", "", regex=True)

    # Chuy·ªÉn s·ªë v·ªÅ d·∫°ng int n·∫øu kh√¥ng c·∫ßn ph·∫ßn th·∫≠p ph√¢n
    for col in ["T·ªìn kho ch∆∞a Mapping SO", "T·ªìn kho Mapping SO", "T·ªïng t·ªìn kho", "S·ªë l∆∞·ª£ng ch·ªù nh·∫≠p kho"]:
        summary[col] = summary[col].astype(int)

    return summary
    # # 5Ô∏è‚É£ Xu·∫•t ra file Excel
    # with pd.ExcelWriter(output_path) as writer:
    #     df_chua_nhap_sum.to_excel(writer, sheet_name="Ch∆∞a nh·∫≠p kho", index=False)
    #     summary.to_excel(writer, sheet_name="T·ªìn kho theo Order", index=False)

# ==============================
# 3. PH√ÇN LO·∫†I TR·∫†NG TH√ÅI
# ==============================
def classify(row):
    if pd.isna(row["SL trung b√¨nh/ng√†y"]):
        return "Ch·ªù LSX m·ªõi"
    if not row.get("Trong_khoang_LSX", False):
        return "Ngo√†i ph·∫°m vi LSX"
    if row["S·∫£n l∆∞·ª£ng th·ª±c t·∫ø"] < row["SL trung b√¨nh/ng√†y"]:
        diff = row["SL trung b√¨nh/ng√†y"] - row["S·∫£n l∆∞·ª£ng th·ª±c t·∫ø"]
        return f"Th·∫•t tho√°t {diff:,.0f} kg"
    elif row["T·ªïng s·∫£n l∆∞·ª£ng th·ª±c t·∫ø"] > row["T·ªïng y√™u c·∫ßu"]:
        diff = row["T·ªïng s·∫£n l∆∞·ª£ng th·ª±c t·∫ø"] - row["T·ªïng y√™u c·∫ßu"]
        return f"V∆∞·ª£t t·ªïng {diff:,.0f} kg"
    else:
        return "ƒê√∫ng/nh·ªânh h∆°n ti·∫øn ƒë·ªô"

# ==============================
# 4. T·ªîNG H·ª¢P B√ÅO C√ÅO

# ==============================
def generate_report(lsx_path, actual_path):
    df_req = process_lsx(lsx_path)                  
    df_daily, total_actual = process_actual(actual_path)  

    # l·∫•y ph·∫°m vi hi·ªáu l·ª±c LSX to√†n c·ª•c
    lsx_start, lsx_end = get_lsx_range_from_file(lsx_path)

    # merge d·ªØ li·ªáu
    df_report = df_daily.merge(df_req, on="Order", how="left")
    df_report = df_report.merge(total_actual, on="Order", how="left")

    # check ph·∫°m vi hi·ªáu l·ª±c LSX
    if lsx_start and lsx_end:
        df_report["Trong_khoang_LSX"] = (
            (df_report["Ng√†y"] >= lsx_start) &
            (df_report["Ng√†y"] <= lsx_end)
        )
    else:
        df_report["Trong_khoang_LSX"] = False

    # üî¥ l·ªçc d·ªØ li·ªáu: gi·ªØ l·∫°i trong kho·∫£ng LSX ho·∫∑c ch∆∞a c√≥ LSX (NaN)
    df_report = df_report[
        df_report["Trong_khoang_LSX"] | df_report["SL trung b√¨nh/ng√†y"].isna()
    ]

    # ph√¢n lo·∫°i tr·∫°ng th√°i
    df_report["Tr·∫°ng th√°i"] = df_report.apply(classify, axis=1)

    return df_report
# ==============================
# 5. CH·∫†Y CH√çNH
# ==============================
# if __name__ == "__main__":
#     generate_report(
#         lsx_path="05.07.2025 LSX XC NM.HRC1 (ok).xlsx",
#         actual_path="ZBC04B_EXPORT_20250805_133956.xlsx"
#     )

# if __name__ == "__main__":
#     xu_ly_ton_kho(
#     file_sanluong="EXPORT_20250812_085402.xlsx",
#     file_kho="ZPP04.xlsx",
#     output_path="ket_qua_ton_kho_theo_order.xlsx"
#     )
#     generate_report(
#         lsx_path="02.08.2025 LSX XC NM.HRC1 1.xlsx",
#         actual_path="EXPORT_20250812_085402.xlsx"
#     )
