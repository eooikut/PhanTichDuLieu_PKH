import pandas as pd
import re
import os
from datetime import datetime
# ==============================
# 1. X·ª¨ L√ù FILE L·ªÜNH S·∫¢N XU·∫§T
# ==============================

import re
import pandas as pd

def get_lsx_range_from_file(file_path, sheet_name=0, row_index=5, col_index=0):
    val = pd.read_excel(file_path, sheet_name=sheet_name, header=None).iloc[row_index, col_index]
    if pd.isna(val):
        return None, None

    text = str(val)
    found = re.findall(r"(\d{2}/\d{2}/\d{4})", text)

    if len(found) >= 2:
        start = pd.to_datetime(found[0], dayfirst=True, errors="coerce")
        end = pd.to_datetime(found[-1], dayfirst=True, errors="coerce")
    elif len(found) == 1:
        start = end = pd.to_datetime(found[0], dayfirst=True, errors="coerce")
    else:
        start = end = None

    return start, end

def extract_dates(val):
    """Tr√≠ch xu·∫•t ng√†y b·∫Øt ƒë·∫ßu/k·∫øt th√∫c t·ª´ chu·ªói th·ªùi gian."""
    if pd.isna(val):
        return None, None

    text = str(val).replace("\n", " ").strip()
    found = re.findall(r"(\d{2}/\d{2}/\d{4})", text)

    if len(found) >= 2:
        start = pd.to_datetime(found[0], dayfirst=True, errors="coerce")
        end = pd.to_datetime(found[-1], dayfirst=True, errors="coerce")
    elif len(found) == 1:
        start = end = pd.to_datetime(found[0], dayfirst=True, errors="coerce")
    else:
        start = end = None

    return start, end


def process_lsx(file_path, sheet_name=3, skip_rows=6):
    """ƒê·ªçc v√† x·ª≠ l√Ω file LSX."""
    time_col = "Th·ªùi gian d·ª± ki·∫øn SX\nTime/Date"
    df = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=skip_rows)

    # ƒêi·ªÅn gi√° tr·ªã th·ªùi gian cho c√°c d√≤ng tr·ªëng
    df[time_col] = df[time_col].ffill()

    # T·∫°o b·∫£ng block_days
    block_days = df[[time_col]].drop_duplicates().copy()
    block_days[["Ng√†y b·∫Øt ƒë·∫ßu block", "Ng√†y k·∫øt th√∫c block"]] = block_days[time_col].apply(
        lambda x: pd.Series(extract_dates(x))
    )

    # √âp ki·ªÉu datetime
    for col in ["Ng√†y b·∫Øt ƒë·∫ßu block", "Ng√†y k·∫øt th√∫c block"]:
        block_days[col] = pd.to_datetime(block_days[col], dayfirst=True, errors="coerce")

    # T√≠nh s·ªë ng√†y y√™u c·∫ßu block
    block_days["S·ªë ng√†y y√™u c·∫ßu block"] = (
        (block_days["Ng√†y k·∫øt th√∫c block"] - block_days["Ng√†y b·∫Øt ƒë·∫ßu block"]).dt.days + 1
    )

    # Merge l·∫°i v√†o df g·ªëc
    df = df.merge(block_days, on=time_col, how="left")
    df["S·ªë Order number"] = df["S·ªë Order number"].ffill()

    # Chuy·ªÉn c·ªôt SL sang s·ªë
    for col in ["Unnamed: 4", "Unnamed: 5"]:
        df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)

    # T√≠nh t·ªïng SL theo block
    agg_df = df.groupby(
        ["S·ªë Order number", "Ng√†y b·∫Øt ƒë·∫ßu block", "Ng√†y k·∫øt th√∫c block", "S·ªë ng√†y y√™u c·∫ßu block"],
        as_index=False
    ).agg({
        "Unnamed: 4": "sum",
        "Unnamed: 5": "sum"
    })

    agg_df["SL y√™u c·∫ßu (t·∫•n)"] = (agg_df["Unnamed: 4"] + agg_df["Unnamed: 5"]) * 1000
    agg_df["SL trung b√¨nh/ng√†y"] = agg_df["SL y√™u c·∫ßu (t·∫•n)"] / agg_df["S·ªë ng√†y y√™u c·∫ßu block"]

    # Chu·∫©n b·ªã d·ªØ li·ªáu ƒë·ªÉ merge
    df_req = agg_df.rename(columns={
        "S·ªë Order number": "Order",
        "SL y√™u c·∫ßu (t·∫•n)": "T·ªïng y√™u c·∫ßu"
    })[["Order", "T·ªïng y√™u c·∫ßu", "SL trung b√¨nh/ng√†y"]]

    return df_req



# ==============================
# 2. X·ª¨ L√ù FILE S·∫¢N L∆Ø·ª¢NG TH·ª∞C T·∫æ
# ==============================
def process_actual(file_path, sheet_name="Data"):
    """ƒê·ªçc v√† x·ª≠ l√Ω file s·∫£n l∆∞·ª£ng th·ª±c t·∫ø."""
    df = pd.read_excel(file_path, sheet_name=sheet_name).dropna(how="all")
    df["Ng√†y s·∫£n xu·∫•t"] = pd.to_datetime(df["Ng√†y s·∫£n xu·∫•t"], errors="coerce")
    df["Kh√¥ÃÅi l∆∞∆°Ã£ng"] = pd.to_numeric(df["Kh√¥ÃÅi l∆∞∆°Ã£ng"], errors="coerce")
    df = df.dropna(subset=["Order", "Ng√†y s·∫£n xu·∫•t"])

    # Gom nh√≥m theo Order v√† Ng√†y
    df_daily = df.groupby(["Order", "Ng√†y s·∫£n xu·∫•t"], as_index=False)["Kh√¥ÃÅi l∆∞∆°Ã£ng"].sum()
    df_daily = df_daily.rename(columns={
        "Kh√¥ÃÅi l∆∞∆°Ã£ng": "S·∫£n l∆∞·ª£ng th·ª±c t·∫ø",
        "Ng√†y s·∫£n xu·∫•t": "Ng√†y"
    })

    # T·ªïng s·∫£n l∆∞·ª£ng theo Order
    total_actual = df_daily.groupby("Order", as_index=False)["S·∫£n l∆∞·ª£ng th·ª±c t·∫ø"].sum()
    total_actual = total_actual.rename(columns={"S·∫£n l∆∞·ª£ng th·ª±c t·∫ø": "T·ªïng s·∫£n l∆∞·ª£ng th·ª±c t·∫ø"})

    return df_daily, total_actual
#3 X·ª¨ L√ù FILE S·∫¢N L∆Ø·ª¢NG KHO

def classify(row):
    if pd.isna(row["SL trung b√¨nh/ng√†y"]):
        return "Ch·ªù LSX m·ªõi"
    if not row.get("Trong_khoang_LSX", False):
        return "Ngo√†i ph·∫°m vi LSX"
    if row["S·∫£n l∆∞·ª£ng th·ª±c t·∫ø"] < row["SL trung b√¨nh/ng√†y"]:
        diff = row["SL trung b√¨nh/ng√†y"] - row["S·∫£n l∆∞·ª£ng th·ª±c t·∫ø"]
        return f"Th·∫•t tho√°t {diff:,.0f} kg"
    elif row["T·ªïng s·∫£n l∆∞·ª£ng th·ª±c t·∫ø"] > row["T·ªïng y√™u c·∫ßu"]:
        diff = row["T·ªïng s·∫£n l∆∞·ª£ng th·ª±c t·∫ø"] - row["T·ªïng y√™u c·∫ßu"]
        return f"V∆∞·ª£t t·ªïng {diff:,.0f} kg"
    else:
        return "ƒê√∫ng/nh·ªânh h∆°n ti·∫øn ƒë·ªô"

# ==============================
# 4. T·ªîNG H·ª¢P B√ÅO C√ÅO

# ==============================
def generate_report(lsx_path, actual_path):
    df_req = process_lsx(lsx_path)                  
    df_daily, total_actual = process_actual(actual_path)  

    lsx_start, lsx_end = get_lsx_range_from_file(lsx_path)

    df_report = df_daily.merge(df_req, on="Order", how="left")
    df_report = df_report.merge(total_actual, on="Order", how="left")

    if lsx_start and lsx_end:
        df_report["Trong_khoang_LSX"] = (
            (df_report["Ng√†y"] >= lsx_start) & 
            (df_report["Ng√†y"] <= lsx_end)
        )
    else:
        df_report["Trong_khoang_LSX"] = False

    df_report = df_report[
        df_report["Trong_khoang_LSX"] | df_report["SL trung b√¨nh/ng√†y"].isna()
    ]

    df_report["Tr·∫°ng th√°i"] = df_report.apply(classify, axis=1)

    # üîπ N·∫øu c√≥ y√™u c·∫ßu th√¨ l∆∞u ra file JSON ƒë·ªÉ gi·ªØ l·ªãch s·ª≠

    return df_report


def xu_ly_ton_kho(file_sanluong, file_kho):

    # ƒê·ªçc d·ªØ li·ªáu
    df_sanluong = pd.read_excel(file_sanluong)
    df_kho = pd.read_excel(file_kho)

    # B·ªè c√°c d√≤ng tr·ªëng ID Cu·ªôn B√≥
    df_kho = df_kho.dropna(subset=["ID Cu·ªôn B√≥"])
    df_sanluong = df_sanluong.dropna(subset=["ID Cu·ªôn B√≥"])

    # Chu·∫©n h√≥a ki·ªÉu d·ªØ li·ªáu
    df_kho["ID Cu·ªôn B√≥"] = df_kho["ID Cu·ªôn B√≥"].astype(str).str.strip()
    df_sanluong["ID Cu·ªôn B√≥"] = df_sanluong["ID Cu·ªôn B√≥"].astype(str).str.strip()

    # 1Ô∏è‚É£ X√°c ƒë·ªãnh cu·ªôn b√≥ ch∆∞a nh·∫≠p kho
    id_kho_set = set(df_kho["ID Cu·ªôn B√≥"].unique())
    df_chua_nhap = df_sanluong[~df_sanluong["ID Cu·ªôn B√≥"].isin(id_kho_set)].copy()

    # G·ªôp theo Order ƒë·ªÉ t√≠nh t·ªïng kh·ªëi l∆∞·ª£ng ch∆∞a nh·∫≠p kho
    df_chua_nhap_sum = df_chua_nhap.groupby("Order").agg(
        S·ªë_l∆∞·ª£ng_ch∆∞a_nh·∫≠p_kho=("Kh√¥ÃÅi l∆∞∆°Ã£ng", "sum"),
        Material_Description=("Material Description", "first")   # L·∫•y m√¥ t·∫£ v·∫≠t li·ªáu
    ).reset_index()

    # 2Ô∏è‚É£ Ph√¢n lo·∫°i t·ªìn kho
    df_kho["T·ªìn kho lo·∫°i"] = df_kho["SO Mapping"].apply(
        lambda x: "Kh√¥ng t·ª± do" if pd.notna(x) else "T·ª± do"
    )

    # 3Ô∏è‚É£ T·ªïng h·ª£p t·ªìn kho theo Order
    summary = df_kho.groupby("Order").agg(
        Material_Description=("Material Description", "first"),  # L·∫•y m√¥ t·∫£ v·∫≠t li·ªáu
        T·ªïng_t·ªìn_kho_t·ª±_do=("Kh√¥ÃÅi l∆∞∆°Ã£ng", lambda x: x[df_kho.loc[x.index, "T·ªìn kho lo·∫°i"] == "T·ª± do"].sum()),
        T·ªïng_t·ªìn_kho_mapping_SO=("Kh√¥ÃÅi l∆∞∆°Ã£ng", lambda x: x[df_kho.loc[x.index, "T·ªìn kho lo·∫°i"] == "Kh√¥ng t·ª± do"].sum()),
        T·ªïng_t·ªìn_kho=("Kh√¥ÃÅi l∆∞∆°Ã£ng", "sum")
    ).reset_index()

    # 4Ô∏è‚É£ Merge th√™m c·ªôt s·ªë l∆∞·ª£ng ch∆∞a nh·∫≠p kho
    summary = summary.merge(df_chua_nhap_sum, on=["Order", "Material_Description"], how="outer").fillna(0)

    # ƒê·ªïi t√™n c·ªôt
    summary = summary.rename(columns={
        "Order": "M√£ Order",
        "Material_Description": "Material Description",  # ‚úÖ s·ª≠a t√™n c·ªôt v·ªÅ gi·ªëng file SO
        "T·ªïng_t·ªìn_kho_t·ª±_do": "T·ªìn kho ch∆∞a Mapping SO",
        "T·ªïng_t·ªìn_kho_mapping_SO": "T·ªìn kho Mapping SO",
        "T·ªïng_t·ªìn_kho": "T·ªïng t·ªìn kho",
        "S·ªë_l∆∞·ª£ng_ch∆∞a_nh·∫≠p_kho": "S·ªë l∆∞·ª£ng ch·ªù nh·∫≠p kho"
})


    # B·ªè .0 trong Order
    summary["M√£ Order"] = summary["M√£ Order"].astype(str).str.replace(r"\.0$", "", regex=True)

    # Chuy·ªÉn s·ªë v·ªÅ d·∫°ng int n·∫øu kh√¥ng c·∫ßn ph·∫ßn th·∫≠p ph√¢n
    for col in ["T·ªìn kho ch∆∞a Mapping SO", "T·ªìn kho Mapping SO", "T·ªïng t·ªìn kho", "S·ªë l∆∞·ª£ng ch·ªù nh·∫≠p kho"]:
        summary[col] = summary[col].astype(int)

    return summary

def process_so_file(file1_path, file2_path):

    # ===== 1. ƒê·ªçc file1 v√† t√≠nh ti·∫øn ƒë·ªô =====
    df1 = pd.read_excel(file1_path, skiprows=2)
    print(f"S·ªë d√≤ng trong file1: {len(df1)}")
    print("C√°c c·ªôt trong file1:", df1.columns.tolist())

    # T√≠nh ti·∫øn ƒë·ªô (Process) cho t·ª´ng SO + Material
    df1['Process'] = df1.apply(
        lambda row: (row['Shipped Quantity (KG)'] / row['Quantity (KG)'] * 100)
        if row['Quantity (KG)'] > 0 else 0,
        axis=1
    ).round(2)

    # Ch·ªâ gi·ªØ c√°c c·ªôt c·∫ßn thi·∫øt
    df1_processed = df1[['Sales Document', 'Material','Shipped Quantity (KG)','Quantity (KG)', 'Process']].copy()

    # ===== 2. ƒê·ªçc file2 (th√¥ng tin Order, Material Description, Customer N) =====
    df2 = pd.read_excel(file2_path)

    # ===== 3. Merge hai DataFrame =====
    merged_df = pd.merge(
        df2,
        df1_processed,
        left_on=['SO Mapping', 'Material'],
        right_on=['Sales Document', 'Material'],
        how='inner'
    )

    # ===== 4. Chu·∫©n h√≥a d·ªØ li·ªáu =====
    for col in ['Order','SO Mapping','Material Description','Customer N','Process']:
        if merged_df[col].dtype == 'object':  # ch·ªâ √°p d·ª•ng v·ªõi c·ªôt chu·ªói
            merged_df[col] = merged_df[col].str.strip()
    
    # Chuy·ªÉn ki·ªÉu d·ªØ li·ªáu
    merged_df['Process'] = merged_df['Process'].astype(float)
    merged_df['Order'] = merged_df['Order'].astype(str)
    merged_df['SO Mapping'] = merged_df['SO Mapping'].astype(str)

    # ===== 5. Lo·∫°i b·ªè tr√πng l·∫∑p =====
    merged_df = merged_df.drop_duplicates(
        subset=['Order','SO Mapping','Material Description','Customer N','Process']
    )

    # ===== 6. L·∫•y c√°c c·ªôt c·∫ßn xu·∫•t =====
    merged_df1 = merged_df[['Order','SO Mapping', 'Material Description','Customer N','Shipped Quantity (KG)','Quantity (KG)','Process']]
    return merged_df1

def xu_ly_ton_kho_full(file_sl, file_kh, file_so):
    # --- B1: X·ª≠ l√Ω file t·ªìn kho ---
    data1 = xu_ly_ton_kho(file_sl, file_kh)
    data1 = data1.rename(columns={"M√£ Order": "Order"})
    data1['Order'] = pd.to_numeric(data1['Order'], errors="coerce").fillna(0).astype(int)

    # --- B2: X·ª≠ l√Ω file SO ---
    data2 = process_so_file(file_so, file_kh)
    data2['Order'] = pd.to_numeric(data2['Order'], errors="coerce").fillna(0).astype(int)

    # --- B3: Merge 2 b·∫£ng ---
    data = pd.merge(
        data1,
        data2,
        how='left',   # Gi·ªØ t·∫•t c·∫£ Order trong data1
        on=["Order", "Material Description"]
    )

    # --- B4: Th√™m d√≤ng "Ch∆∞a c√≥ SO" cho t·ªìn kho ch∆∞a mapping ---
    rows_to_add = []
    for _, row in data1.iterrows():
        if row["T·ªìn kho Mapping SO"] == 0:
            rows_to_add.append({
                "Order": row["Order"],
                "T·ªìn kho ch∆∞a Mapping SO": row["T·ªìn kho ch∆∞a Mapping SO"],
                "T·ªìn kho Mapping SO": row["T·ªìn kho Mapping SO"],
                "T·ªïng t·ªìn kho": row["T·ªïng t·ªìn kho"],
                "S·ªë l∆∞·ª£ng ch·ªù nh·∫≠p kho": row["S·ªë l∆∞·ª£ng ch·ªù nh·∫≠p kho"],
                "SO Mapping": "Ch∆∞a c√≥ SO",
                "Material Description": row["Material Description"],
                "Customer N": "Ch∆∞a c√≥ SO",
                "Shipped Quantity (KG)": 0,
                "Quantity (KG)": 0,
                "Process": 0
            })

    if rows_to_add:
        data = pd.concat([data, pd.DataFrame(rows_to_add)], ignore_index=True)

    # --- B5: Fill NaN ---
    data = data.fillna({
        "SO Mapping": "Ch∆∞a c√≥ SO",
        "Shipped Quantity (KG)": 0,
        "Quantity (KG)": 0,
        "Process": 0
    })

    # --- B6: √âp ki·ªÉu s·ªë cho c√°c c·ªôt s·ªë ---
    num_cols = [
        "T·ªìn kho ch∆∞a Mapping SO","T·ªìn kho Mapping SO","T·ªïng t·ªìn kho","SO Mapping",
        "S·ªë l∆∞·ª£ng ch·ªù nh·∫≠p kho","Shipped Quantity (KG)",
        "Quantity (KG)","Process"
    ]
    for col in num_cols:
        data[col] = pd.to_numeric(data[col], errors="coerce").fillna(0).astype(int)

    return data
def load_data(file_sl, file_kh, file_so):
    df=xu_ly_ton_kho_full(file_sl, file_kh, file_so)
    # Sort d·ªØ li·ªáu
    df = df.sort_values(by=['Order', 'Material Description', 'SO Mapping'])

    grouped = []
    for (order, material), group in df.groupby(['Order','Material Description']):
        grouped.append({
            'Order': order,
            'Material': material,
            'TonKhoChuaMapping': group['T·ªìn kho ch∆∞a Mapping SO'].iloc[0],
            'TonKhoMapping': group['T·ªìn kho Mapping SO'].iloc[0],
            'TongTonKho': group['T·ªïng t·ªìn kho'].iloc[0],
            'ChoNhapKho': group['S·ªë l∆∞·ª£ng ch·ªù nh·∫≠p kho'].iloc[0],
            'SOs': group[['SO Mapping','Shipped Quantity (KG)','Quantity (KG)','Process']].to_dict(orient='records')
        })
    return grouped

